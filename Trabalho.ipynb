{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/degar405/AgenteInteligenteLinkMasterSword/blob/main/Trabalho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-image"
      ],
      "metadata": {
        "id": "n5fYe-dRF__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de mapas de textura e funções úteis**"
      ],
      "metadata": {
        "id": "viyDEZIyISD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCMMSauvae1t"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from os import listdir\n",
        "from skimage import io\n",
        "import pywt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import graycomatrix\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "def exibirImagensCoeficientesWavelet(coeffs):\n",
        "  titles = ['Approximation', ' Horizontal detail',\n",
        "          'Vertical detail', 'Diagonal detail']\n",
        "  LL, (LH, HL, HH) = coeffs\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 3))\n",
        "  for i, a in enumerate([LL, LH, HL, HH]):\n",
        "      ax = fig.add_subplot(1, 4, i + 1)\n",
        "      ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n",
        "      ax.set_title(titles[i], fontsize=10)\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def separarCanaisRGB(imagem):\n",
        "  canalR = []\n",
        "  canalG = []\n",
        "  canalB = []\n",
        "\n",
        "  for linha in imagem:\n",
        "    linhaR = []\n",
        "    linhaG = []\n",
        "    linhaB = []\n",
        "\n",
        "    for pixel in linha:\n",
        "      linhaR.append(pixel[0])\n",
        "      linhaG.append(pixel[1])\n",
        "      linhaB.append(pixel[2])\n",
        "\n",
        "    canalR.append(linhaR)\n",
        "    canalG.append(linhaG)\n",
        "    canalB.append(linhaB)\n",
        "  \n",
        "  return (np.array(canalR), np.array(canalG), np.array(canalB))\n",
        "\n",
        "def aplicarWavelet(imagem, implementacao):\n",
        "  return pywt.dwt2(imagem, implementacao)\n",
        "\n",
        "def combinarImagensEmTonsDeCinza(R, G, B):\n",
        "  imagem = []\n",
        "  quantidadeLinhas = len(R)\n",
        "  quantidadeColunas = len(R[0])\n",
        "\n",
        "  for nLinha in range(0, quantidadeLinhas):\n",
        "    linha = []\n",
        "\n",
        "    for nColuna in range(0, quantidadeColunas):\n",
        "      pixel = round(0.2126 * R[nLinha][nColuna] + 0.7154 * G[nLinha][nColuna] + 0.0721 * B[nLinha][nColuna])\n",
        "      linha.append(pixel)\n",
        "\n",
        "    imagem.append(linha)\n",
        "\n",
        "  return imagem\n",
        "\n",
        "def combinarCoeficientesWavelet(coeficientesR, coeficientesG, coeficientesB):\n",
        "  (LLR, (LHR, HLR, HHR)) = coeficientesR\n",
        "  (LLG, (LHG, HLG, HHG)) = coeficientesG\n",
        "  (LLB, (LHB, HLB, HHB)) = coeficientesB\n",
        "\n",
        "  LL = combinarImagensEmTonsDeCinza(LLR, LLG, LLB)\n",
        "  LH = combinarImagensEmTonsDeCinza(LHR, LHG, LHB)\n",
        "  HL = combinarImagensEmTonsDeCinza(HLR, HLG, HLB)\n",
        "  HH = combinarImagensEmTonsDeCinza(HHR, HHG, HHB)\n",
        "\n",
        "  return (LL, (LH, HL, HH))\n",
        "\n",
        "def aplicarGlcm(imagem):\n",
        "  distancias = [1]\n",
        "  direcoes = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "  resultadoGlcm = graycomatrix(np.array(imagem, dtype=np.uint8), distancias, direcoes)\n",
        "\n",
        "  qtdDirecoes = len(direcoes)\n",
        "  matrizes = []\n",
        "  for i in range(0, qtdDirecoes):\n",
        "    matrizes.append(resultadoGlcm[:, :, 0, i])\n",
        "\n",
        "  niveis = len(matrizes[0])\n",
        "  matrizRetorno = []\n",
        "  for nLinha in range(0, niveis):\n",
        "    linha = []\n",
        "    for nColuna in range(0, niveis):\n",
        "      acumuladorFrequencia = 0\n",
        "      for matriz in matrizes:\n",
        "        acumuladorFrequencia += matriz[nLinha, nColuna]\n",
        "      linha.append(round(acumuladorFrequencia/qtdDirecoes))\n",
        "    matrizRetorno.append(linha)\n",
        "\n",
        "  matrizRetorno = np.array(matrizRetorno)\n",
        "  return matrizRetorno\n",
        "\n",
        "def aplicarDescritoresDeTextura(imagem, implementacaoWavelet):\n",
        "  (canalR, canalG, canalB) = separarCanaisRGB(imagem)\n",
        "\n",
        "  coeficientesWaveletR = aplicarWavelet(canalR, implementacaoWavelet)\n",
        "  coeficientesWaveletG = aplicarWavelet(canalG, implementacaoWavelet)\n",
        "  coeficientesWaveletB = aplicarWavelet(canalB, implementacaoWavelet)\n",
        "\n",
        "  coeficientesWavelet = combinarCoeficientesWavelet(coeficientesWaveletR, coeficientesWaveletG, coeficientesWaveletB)\n",
        "\n",
        "  #exibirImagensCoeficientesWavelet(coeficientesWavelet)\n",
        "  LL, (LH , HL, HH) = coeficientesWavelet\n",
        "  return (aplicarGlcm(LL), aplicarGlcm(LH), aplicarGlcm(HL), aplicarGlcm(HH))\n",
        "\n",
        "def calcularAcc(resultadoClassificador, resultado):\n",
        "  corretos = 0\n",
        "  for i in range(len(resultado)):\n",
        "    if resultadoClassificador[i] == resultado[i]:\n",
        "      corretos += 1\n",
        "\n",
        "  return float(corretos) / len(resultado)\n",
        "\n",
        "def unir4MatrizesNxN(m1, m2, m3, m4):\n",
        "  matrizSuperior = []\n",
        "  matrizInferior = []\n",
        "\n",
        "  for i in range(len(m1)):\n",
        "    matrizSuperior.append(m1[i].tolist() + m2[i].tolist())\n",
        "    matrizInferior.append(m3[i].tolist() + m4[i].tolist())\n",
        "\n",
        "  return matrizSuperior + matrizInferior\n",
        "\n",
        "def normalizarMatriz(matriz):\n",
        "  npMatriz = np.matrix(matriz)\n",
        "  mx, mn = npMatriz.max(), npMatriz.min()\n",
        "  n = len(matriz)\n",
        "  qtd = (mx - mn + 1)\n",
        "  diff = 255 / qtd\n",
        "\n",
        "  resultado = []\n",
        "  for i in range(n):\n",
        "    linha = []\n",
        "    for j in range(n):\n",
        "      linha.append(int(diff * matriz[i][j]))\n",
        "    resultado.append(linha)\n",
        "\n",
        "  return resultado\n",
        "\n",
        "def gerarMatrizFormatoResnet(matriz):\n",
        "  matrizResultado = []\n",
        "  for l in matriz:\n",
        "    linha = []\n",
        "    for e in l:\n",
        "      linha.append([e,e,e])\n",
        "    matrizResultado.append(linha)\n",
        "\n",
        "  return np.array(matrizResultado)\n",
        "\n",
        "def TesteMapasDeTextura():\n",
        "  imagemTeste = io.imread(root_path + \"Normal/Im001.jpg\")\n",
        "  io.imshow(imagemTeste)\n",
        "  io.show()\n",
        "\n",
        "  LL, LH, HL, HH = aplicarDescritoresDeTextura(imagemTeste, \"haar\")\n",
        "  matriz = unir4MatrizesNxN(LL, LH, HL, HH)\n",
        "  matrizNormalizada = normalizarHistograma(matriz)\n",
        "\n",
        "  print(len(matrizNormalizada))\n",
        "  print(len(matrizNormalizada[0]))\n",
        "  print(matriz[0])\n",
        "  print(matrizNormalizada[0])\n",
        "  print(matriz[511])\n",
        "  print(matrizNormalizada[511])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geração casos de treinamento e de teste Mapas de Textura**"
      ],
      "metadata": {
        "id": "KvuzCOHXIb3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "amostrasNormaisMapasTextura = []\n",
        "for i in range(1, 256):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Normal/\" + nomeArquivo)\n",
        "  LL, LH, HL, HH = aplicarDescritoresDeTextura(imagem, \"haar\")\n",
        "  amostrasNormaisMapasTextura.append(LL.flatten() + LH.flatten() + HL.flatten() + HH.flatten())\n",
        "\n",
        "amostrasGlaucomatosasMapasTextura = []\n",
        "for i in range(256, 456):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Glaucoma and glaucoma suspicious/\" + nomeArquivo)\n",
        "  LL, LH, HL, HH = aplicarDescritoresDeTextura(imagem, \"haar\")\n",
        "  amostrasGlaucomatosasMapasTextura.append(LL.flatten() + LH.flatten() + HL.flatten() + HH.flatten())"
      ],
      "metadata": {
        "id": "kfU0QA2LbU8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = 1.0 * RBF(1.0)\n",
        "gpcMapasTextura = GaussianProcessClassifier(kernel=kernel, random_state=0)\n",
        "\n",
        "quotaTreinamentoNormaisMapasTextura = round(0.8 * len(amostrasNormaisMapasTextura))\n",
        "quotaTreinamentoGlaucomatosasMapasTextura = round(0.8 * len(amostrasGlaucomatosasMapasTextura))\n",
        "amostrasMapasTextura = amostrasNormaisMapasTextura[:quotaTreinamentoNormaisMapasTextura] + amostrasGlaucomatosasMapasTextura[:quotaTreinamentoGlaucomatosasMapasTextura]\n",
        "saidaAmostrasMapasTextura = [0 for i in range(quotaTreinamentoNormaisMapasTextura)] + [1 for i in range(quotaTreinamentoGlaucomatosasMapasTextura)]\n",
        "gpcMapasTextura.fit(amostrasMapasTextura, saidaAmostrasMapasTextura)\n",
        "\n",
        "amostrasTesteMapasTextura = amostrasNormaisMapasTextura[quotaTreinamentoNormaisMapasTextura:] + amostrasGlaucomatosasMapasTextura[quotaTreinamentoGlaucomatosasMapasTextura:]\n",
        "saidaAmostrasTesteMapasTextura = [0 for i in range(len(amostrasNormaisMapasTextura) - quotaTreinamentoNormaisMapasTextura)] + [1 for i in range(len(amostrasGlaucomatosasMapasTextura) - quotaTreinamentoGlaucomatosasMapasTextura)]\n",
        "\n",
        "predicaoTesteMapasTextura = gpcMapasTextura.predict(amostrasTesteMapasTextura)"
      ],
      "metadata": {
        "id": "RKVWFFOHvbho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "166ZctgaCipb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geração casos de treinamento e de teste Resnet50 com imagem pura**"
      ],
      "metadata": {
        "id": "onMofue4JIp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import gridspec\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "\n",
        "model = ResNet50(weights = 'imagenet', include_top = False)\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "amostrasNormaisResnet = []\n",
        "for i in range(1, 256):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Normal/\" + nomeArquivo)\n",
        "  # Convert image to RGB from BGR (another way is to use \"image = image[:, :, ::-1]\" code)\n",
        "  imagem = cv.cvtColor(imagem, cv.COLOR_BGR2RGB)\n",
        "\n",
        "  # Resize image to 224x224 size\n",
        "  image = cv.resize(imagem, (224, 224)).reshape(-1, 224, 224, 3)\n",
        "\n",
        "  # We need to preprocess imageto fulfill ResNet50 requirements\n",
        "  image = preprocess_input(image)\n",
        "\n",
        "  # Extracting our features\n",
        "  features = model.predict(image)\n",
        "  amostrasNormaisResnet.append(features.flatten())\n",
        "\n",
        "amostrasGlaucomatosasResnet = []\n",
        "for i in range(256, 456):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Glaucoma and glaucoma suspicious/\" + nomeArquivo)\n",
        "  # Convert image to RGB from BGR (another way is to use \"image = image[:, :, ::-1]\" code)\n",
        "  imagem = cv.cvtColor(imagem, cv.COLOR_BGR2RGB)\n",
        "\n",
        "  # Resize image to 224x224 size\n",
        "  image = cv.resize(imagem, (224, 224)).reshape(-1, 224, 224, 3)\n",
        "\n",
        "  # We need to preprocess imageto fulfill ResNet50 requirements\n",
        "  image = preprocess_input(image)\n",
        "\n",
        "  # Extracting our features\n",
        "  features = model.predict(image)\n",
        "  amostrasGlaucomatosasResnet.append(features.flatten())\n"
      ],
      "metadata": {
        "id": "_BrrO4_KBbWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcResnet = GaussianProcessClassifier()\n",
        "\n",
        "quotaTreinamentoNormaisResnet = round(0.8 * len(amostrasNormaisResnet))\n",
        "quotaTreinamentoGlaucomatosasResnet = round(0.8 * len(amostrasGlaucomatosasResnet))\n",
        "amostrasResnet = amostrasGlaucomatosasResnet[:quotaTreinamentoGlaucomatosasResnet] + amostrasNormaisResnet[:quotaTreinamentoNormaisResnet]\n",
        "saidaAmostrasResnet = [1 for i in range(quotaTreinamentoGlaucomatosasResnet)] + [0 for i in range(quotaTreinamentoNormaisResnet)]\n",
        "gpcResnet.fit(amostrasResnet, saidaAmostrasResnet)\n",
        "\n",
        "amostrasTesteResnet = amostrasNormaisResnet[quotaTreinamentoNormaisResnet:] + amostrasGlaucomatosasResnet[quotaTreinamentoGlaucomatosasResnet:]\n",
        "saidaAmostrasTesteResnet = [0 for i in range(len(amostrasNormaisResnet) - quotaTreinamentoNormaisResnet)] + [1 for i in range(len(amostrasGlaucomatosasResnet) - quotaTreinamentoGlaucomatosasResnet)]\n",
        "\n",
        "predicaoTesteResnet = gpcResnet.predict(amostrasTesteResnet)\n",
        "gpcResnet.predict_proba(amostrasResnet)"
      ],
      "metadata": {
        "id": "9ehYC-96IPEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aplicação de descritores de textura com unificação das matrizes geradas**"
      ],
      "metadata": {
        "id": "atAPV32hSbcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "mapasTexturaUnificadosNormais = []\n",
        "for i in range(1, 256):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Normal/\" + nomeArquivo)\n",
        "  LL, LH, HL, HH = aplicarDescritoresDeTextura(imagem, \"haar\")\n",
        "  mapasTexturaUnificadosNormais.append(unir4MatrizesNxN(LL, LH, HL, HH))\n",
        "\n",
        "mapasTexturaUnificadosGlaucomatosas = []\n",
        "for i in range(256, 456):\n",
        "  nomeArquivo = \"Im\" + str(i).rjust(3, \"0\") + \".jpg\"\n",
        "  imagem = io.imread(root_path + \"Glaucoma and glaucoma suspicious/\" + nomeArquivo)\n",
        "  LL, LH, HL, HH = aplicarDescritoresDeTextura(imagem, \"haar\")\n",
        "  mapasTexturaUnificadosGlaucomatosas.append(unir4MatrizesNxN(LL, LH, HL, HH))"
      ],
      "metadata": {
        "id": "we-j0H4kSoN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geração casos de treinamento e de teste WcgResnet**"
      ],
      "metadata": {
        "id": "gYMbefHal6fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "model = ResNet50(weights = 'imagenet', include_top = False)\n",
        "\n",
        "amostrasWcgResnetNormais = []\n",
        "for caso in mapasTexturaUnificadosNormais:\n",
        "  image = cv.resize(gerarMatrizFormatoResnet(caso), (512, 512)).reshape(-1, 512, 512, 3)\n",
        "  image = preprocess_input(image)\n",
        "  features = model.predict(image)\n",
        "  amostrasWcgResnetNormais.append(features.flatten())\n",
        "\n",
        "amostrasWcgResnetGlaucomatosas = []\n",
        "for caso in mapasTexturaUnificadosGlaucomatosas:\n",
        "  image = cv.resize(gerarMatrizFormatoResnet(caso), (512, 512)).reshape(-1, 512, 512, 3)\n",
        "  image = preprocess_input(image)\n",
        "  features = model.predict(image)\n",
        "  amostrasWcgResnetGlaucomatosas.append(features.flatten())\n",
        "\n",
        "quotaTreinamentoWcgResnetNormais = round(0.8 * len(amostrasWcgResnetNormais))\n",
        "quotaTreinamentoWcgResnetGlaucomatosas = round(0.8 * len(amostrasWcgResnetGlaucomatosas))\n",
        "\n",
        "amostrasWcgResnet = amostrasWcgResnetNormais[:quotaTreinamentoWcgResnetNormais] + amostrasWcgResnetGlaucomatosas[:quotaTreinamentoWcgResnetGlaucomatosas]\n",
        "saidaAmostrasWcgResnet = [0 for i in range(quotaTreinamentoWcgResnetNormais)] + [1 for i in range(quotaTreinamentoWcgResnetGlaucomatosas)]\n",
        "\n",
        "amostrasTesteWcgResnet = amostrasWcgResnetNormais[quotaTreinamentoWcgResnetNormais:] + amostrasWcgResnetGlaucomatosas[quotaTreinamentoWcgResnetGlaucomatosas:]\n",
        "saidaAmostrasTesteWcgResnet = [0 for i in range(len(amostrasWcgResnetNormais) - quotaTreinamentoWcgResnetNormais)] + [1 for i in range(len(amostrasWcgResnetGlaucomatosas) - quotaTreinamentoWcgResnetGlaucomatosas)]"
      ],
      "metadata": {
        "id": "HR81P3TRmI3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geração casos de treinamento e de teste WcgNormResnet**"
      ],
      "metadata": {
        "id": "-gdW-KoZoS2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/gdrive/My Drive/Colab Notebooks/Trabalho/'\n",
        "\n",
        "model = ResNet50(weights = 'imagenet', include_top = False)\n",
        "\n",
        "amostrasWcgNormResnetNormais = []\n",
        "for caso in mapasTexturaUnificadosNormais:\n",
        "  image = cv.resize(gerarMatrizFormatoResnet(normalizarMatriz(caso)), (512, 512)).reshape(-1, 512, 512, 3)\n",
        "  image = preprocess_input(image)\n",
        "  features = model.predict(image)\n",
        "  amostrasWcgNormResnetNormais.append(features.flatten())\n",
        "\n",
        "amostrasWcgNormResnetGlaucomatosas = []\n",
        "for caso in mapasTexturaUnificadosGlaucomatosas:\n",
        "  image = cv.resize(gerarMatrizFormatoResnet(normalizarMatriz(caso)), (512, 512)).reshape(-1, 512, 512, 3)\n",
        "  image = preprocess_input(image)\n",
        "  features = model.predict(image)\n",
        "  amostrasWcgNormResnetGlaucomatosas.append(features.flatten())\n",
        "\n",
        "quotaTreinamentoWcgNormResnetNormais = round(0.8 * len(amostrasWcgNormResnetNormais))\n",
        "quotaTreinamentoWcgNormResnetGlaucomatosas = round(0.8 * len(amostrasWcgNormResnetGlaucomatosas))\n",
        "\n",
        "amostrasWcgNormResnet = amostrasWcgNormResnetNormais[:quotaTreinamentoWcgNormResnetNormais] + amostrasWcgNormResnetGlaucomatosas[:quotaTreinamentoWcgNormResnetGlaucomatosas]\n",
        "saidaAmostrasWcgNormResnet = [0 for i in range(quotaTreinamentoWcgNormResnetNormais)] + [1 for i in range(quotaTreinamentoWcgNormResnetGlaucomatosas)]\n",
        "\n",
        "amostrasTesteWcgNormResnet = amostrasWcgNormResnetNormais[quotaTreinamentoWcgNormResnetNormais:] + amostrasWcgNormResnetGlaucomatosas[quotaTreinamentoWcgNormResnetGlaucomatosas:]\n",
        "saidaAmostrasTesteWcgNormResnet = [0 for i in range(len(amostrasWcgNormResnetNormais) - quotaTreinamentoWcgNormResnetNormais)] + [1 for i in range(len(amostrasWcgNormResnetGlaucomatosas) - quotaTreinamentoWcgNormResnetGlaucomatosas)]"
      ],
      "metadata": {
        "id": "q3dyxo0Poam9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG + DT**"
      ],
      "metadata": {
        "id": "sN9SBOVOJokC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def executarWcgDt():\n",
        "  dtMapasTextura = tree.DecisionTreeClassifier()\n",
        "  dtMapasTextura = dtMapasTextura.fit(amostrasMapasTextura, saidaAmostrasMapasTextura)\n",
        "  predicaoDtMapasTextura = dtMapasTextura.predict(amostrasTesteMapasTextura)\n",
        "  return (calcularAcc(predicaoDtMapasTextura,saidaAmostrasTesteMapasTextura), cohen_kappa_score(predicaoDtMapasTextura, saidaAmostrasTesteMapasTextura))\n",
        "\n",
        "accWcgDt = 0\n",
        "kappaWcgDt = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgDt()\n",
        "  accWcgDt += acc\n",
        "  kappaWcgDt += kappa\n",
        "\n",
        "print(accWcgDt/10)\n",
        "print(kappaWcgDt/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlzbjreZ1loB",
        "outputId": "666baef1-0939-4979-9987-c7700de68951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6945054945054945\n",
            "0.3962972284477838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resnet50 + DT**"
      ],
      "metadata": {
        "id": "FxYn0YBkOdmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def executarResnetDt():\n",
        "  dtResnet = tree.DecisionTreeClassifier()\n",
        "  dtResnet = dtResnet.fit(amostrasResnet, saidaAmostrasResnet)\n",
        "  predicaoDtResnet = dtResnet.predict(amostrasTesteResnet)\n",
        "  return (calcularAcc(predicaoDtResnet,saidaAmostrasTesteResnet), cohen_kappa_score(predicaoDtResnet, saidaAmostrasTesteResnet))\n",
        "\n",
        "accResnetDt = 0\n",
        "kappaResnetDt = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarResnetDt()\n",
        "  accResnetDt += acc\n",
        "  kappaResnetDt += kappa\n",
        "\n",
        "print(accResnetDt/10)\n",
        "print(kappaResnetDt/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anPuyjjO3EjQ",
        "outputId": "d783e92f-7c3b-4b99-8cb1-9c224ea8f1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7527472527472527\n",
            "0.5111744858562731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG + Resnet50 + DT**"
      ],
      "metadata": {
        "id": "bz2PVhSvpSzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def executarWcgResnetDt():\n",
        "  dtWcgResnet = tree.DecisionTreeClassifier()\n",
        "  dtWcgResnet = dtWcgResnet.fit(amostrasWcgResnet, saidaAmostrasWcgResnet)\n",
        "  predicaoDtWcgResnet = dtWcgResnet.predict(amostrasTesteWcgResnet)\n",
        "  return (calcularAcc(predicaoDtWcgResnet,saidaAmostrasTesteWcgResnet), cohen_kappa_score(predicaoDtWcgResnet, saidaAmostrasTesteWcgResnet))\n",
        "\n",
        "accWcgResnetDt = 0\n",
        "kappaWcgResnetDt = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgResnetDt()\n",
        "  accWcgResnetDt += acc\n",
        "  kappaWcgResnetDt += kappa\n",
        "\n",
        "print(accWcgResnetDt/10)\n",
        "print(kappaWcgResnetDt/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPVb8pIXpSZk",
        "outputId": "f59d51f6-984f-4c37-c8f4-46b1d534dade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6670329670329672\n",
            "0.3263401886416099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG Normalizado + Resnet50 + DT**"
      ],
      "metadata": {
        "id": "eDd3N6icqjX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def executarWcgNormResnetDt():\n",
        "  dtWcgNormResnet = tree.DecisionTreeClassifier()\n",
        "  dtWcgNormResnet = dtWcgNormResnet.fit(amostrasWcgNormResnet, saidaAmostrasWcgNormResnet)\n",
        "  predicaoDtWcgNormResnet = dtWcgNormResnet.predict(amostrasTesteWcgNormResnet)\n",
        "  return (calcularAcc(predicaoDtWcgNormResnet,saidaAmostrasTesteWcgNormResnet), cohen_kappa_score(predicaoDtWcgNormResnet, saidaAmostrasTesteWcgNormResnet))\n",
        "\n",
        "accWcgNormResnetDt = 0\n",
        "kappaWcgNormResnetDt = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgNormResnetDt()\n",
        "  accWcgNormResnetDt += acc\n",
        "  kappaWcgNormResnetDt += kappa\n",
        "\n",
        "print(accWcgNormResnetDt/10)\n",
        "print(kappaWcgNormResnetDt/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3E6IYIDrzXM",
        "outputId": "9fcbc64f-d192-49c8-9986-7c047670e910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7252747252747254\n",
            "0.4359730291913454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG + RF**"
      ],
      "metadata": {
        "id": "JbneCHUjOezS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def executarWcgRf():\n",
        "  rfMapasTextura = RandomForestClassifier()\n",
        "  rfMapasTextura = rfMapasTextura.fit(amostrasMapasTextura, saidaAmostrasMapasTextura)\n",
        "  predicaoRfMapasTextura = rfMapasTextura.predict(amostrasTesteMapasTextura)\n",
        "  return (calcularAcc(predicaoRfMapasTextura,saidaAmostrasTesteMapasTextura), cohen_kappa_score(predicaoRfMapasTextura, saidaAmostrasTesteMapasTextura))\n",
        "\n",
        "accWcgRf = 0\n",
        "kappaWcgRf = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgRf()\n",
        "  accWcgRf += acc\n",
        "  kappaWcgRf += kappa\n",
        "\n",
        "print(accWcgRf/10)\n",
        "print(kappaWcgRf/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG9qVAKmOkkG",
        "outputId": "73ceef4a-7b11-4945-8c7f-a674798f68f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7505494505494505\n",
            "0.4929706902890308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resnet50 + RF**"
      ],
      "metadata": {
        "id": "HKsaMol6OlDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def executarResnetRf():\n",
        "  rfResnet = RandomForestClassifier()\n",
        "  rfResnet = rfResnet.fit(amostrasResnet, saidaAmostrasResnet)\n",
        "  predicaoRfResnet = rfResnet.predict(amostrasTesteResnet)\n",
        "  return (calcularAcc(predicaoRfResnet,saidaAmostrasTesteResnet), cohen_kappa_score(predicaoRfResnet, saidaAmostrasTesteResnet))\n",
        "\n",
        "accResnetRf = 0\n",
        "kappaResnetRf = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarResnetRf()\n",
        "  accResnetRf += acc\n",
        "  kappaResnetRf += kappa\n",
        "\n",
        "print(accResnetRf/10)\n",
        "print(kappaResnetRf/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yctplEqqOny9",
        "outputId": "d0f7e2b5-0837-4fa6-9dd4-9c2d90709c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8087912087912088\n",
            "0.6185823840371965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG + Resnet50 + RF**"
      ],
      "metadata": {
        "id": "NGTkLg4WOoYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def executarWcgResnetRf():\n",
        "  rfWcgResnet = RandomForestClassifier()\n",
        "  rfWcgResnet = rfWcgResnet.fit(amostrasWcgResnet, saidaAmostrasWcgResnet)\n",
        "  predicaoRfWcgResnet = rfWcgResnet.predict(amostrasTesteWcgResnet)\n",
        "  return (calcularAcc(predicaoRfWcgResnet,saidaAmostrasTesteWcgResnet), cohen_kappa_score(predicaoRfWcgResnet, saidaAmostrasTesteWcgResnet))\n",
        "\n",
        "accWcgResnetRf = 0\n",
        "kappaWcgResnetRf = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgResnetRf()\n",
        "  accWcgResnetRf += acc\n",
        "  kappaWcgResnetRf += kappa\n",
        "\n",
        "print(accWcgResnetRf/10)\n",
        "print(kappaWcgResnetRf/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_6QdusHOrGX",
        "outputId": "8b3c09be-81c5-43e1-c917-d23c6b9e1c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7274725274725276\n",
            "0.4483838513795769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WCG Normalizado + Resnet50 + RF**"
      ],
      "metadata": {
        "id": "k7ZSXEifOrVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def executarWcgNormResnetRf():\n",
        "  rfWcgNormResnet = RandomForestClassifier()\n",
        "  rfWcgNormResnet = rfWcgNormResnet.fit(amostrasWcgNormResnet, saidaAmostrasWcgNormResnet)\n",
        "  predicaoRfWcgNormResnet = rfWcgNormResnet.predict(amostrasTesteWcgNormResnet)\n",
        "  return (calcularAcc(predicaoRfWcgNormResnet,saidaAmostrasTesteWcgNormResnet), cohen_kappa_score(predicaoRfWcgNormResnet, saidaAmostrasTesteWcgNormResnet))\n",
        "\n",
        "accWcgNormResnetRf = 0\n",
        "kappaWcgNormResnetRf = 0\n",
        "for i in range(10):\n",
        "  acc, kappa = executarWcgNormResnetRf()\n",
        "  accWcgNormResnetRf += acc\n",
        "  kappaWcgNormResnetRf += kappa\n",
        "\n",
        "print(accWcgNormResnetRf/10)\n",
        "print(kappaWcgNormResnetRf/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpbZ_NkSOtrq",
        "outputId": "0b538f49-ca7b-4348-f0e1-da9326395725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.698901098901099\n",
            "0.3865925823440232\n"
          ]
        }
      ]
    }
  ]
}